\relax 
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{shannon51}{1}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction - AGI}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}the AGI will have a goal to maximize}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}AGI is superintelligent}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}goals of AGI are unalignable with human goals}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-D}}Goal is unchangable once the AGI is instanciated}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-E}}AGI will escape controllable environments}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}The first AGI is unlikely to be secure}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Conclusion - AGI}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Results}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{1}}
\@writefile{toc}{\contentsline {section}{References}{1}}
